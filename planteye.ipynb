{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F500 PlantEye data processing\n",
    "\n",
    "This notebooks shows how to process the F500 data using the ISA-JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Read packages and the ISA-JSON with all the project meta.\n",
    "Please set `threshold_date` to the start of the experiment. In some case there were trial measurements which you don't need to use your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "import isatools\n",
    "from isatools.model import *\n",
    "from isatools import isajson\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "\n",
    "isa_json = \"location to JSON\"\n",
    "metadata_file = \"project_metadata.csv\"\n",
    "threshold_date = dt.datetime(2021, 1, 1)\n",
    "\n",
    "\n",
    "investigation = isajson.load(open(isa_json, \"r\"))\n",
    "study = investigation.studies[0]\n",
    "\n",
    "# @TODO: this needs to be added to the JSON as data file to the study\n",
    "metadata = pd.read_csv(metadata_file, delimiter = \";\", engine = \"python\")\n",
    "metadata[['Pot']] = metadata['DataMatrix'].str.split(\" \", expand=True)\n",
    "metadata = metadata.drop('DataMatrix', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotopic data\n",
    "\n",
    "Read all phenotypic data into a single pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "phenotypic_data = None\n",
    "for assay in study.assays:\n",
    "    sample_name = assay.samples[0].name\n",
    "    timepoint = assay.filename\n",
    "    title = assay.title\n",
    "    for df in assay.data_files:\n",
    "        for com in df.comments:\n",
    "            if com.name == \"fullPath\" and \"/\" + title + \".csv\" in com.value:\n",
    "                assay_data = pd.read_csv(com.value, header=0, delimiter=\";\")\n",
    "                if phenotypic_data == None:\n",
    "                    phenotypic_data = assay_data\n",
    "                else:\n",
    "                    phenotypic_data = pandas.concat([phenotypic_data, assay_data]\n",
    "\n",
    "phenotypic_data = pd.merge(phenotypic_data, metadata, on='Pot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def concatenate_columns(row, x, y):\n",
    "    return f\"{row[x]}, {row[y]}\"\n",
    "\n",
    "phenotypic_data[\"Treatment\"] = phenotypic_data[\"Treatment_y\"]\n",
    "phenotypic_data[\"timestamp\"]= phenotypic_data[\"timestamp\"].apply(lambda x: dt.datetime.strptime(x, '%Y%m%dT%H%M%S'))\n",
    "phenotypic_data[\"day\"] = phenotypic_data[\"timestamp\"].dt.date\n",
    "phenotypic_data['timestamp_hourly'] = phenotypic_data['timestamp'].dt.floor('h')\n",
    "phenotypic_data = phenotypic_data[phenotypic_data[\"timestamp\"] >= threshold_date]\n",
    "\n",
    "phenotypic_data[\"Treatment, genotype\"] =  phenotypic_data.apply(concatenate_columns, axis=1, x='Treatment', y='Genotype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of data points: {len(phenotypic_data[\"timestamp\"])}')\n",
    "print(f'Number of different genotypes: {len(phenotypic_data[\"Genotype\"].unique())}')\n",
    "print(f'List of genotypes: {phenotypic_data[\"Genotype\"].unique()}')\n",
    "print(f'Maximum height: {max(phenotypic_data[\"height_max\"].dropna())}')\n",
    "print(f'Minimum maximum height: {min(phenotypic_data[\"height_max\"].dropna())}')\n",
    "print(f'Average maximum height: {np.mean(phenotypic_data[\"height_max\"].dropna())}')\n",
    "print(f'Treatments: {phenotypic_data[\"Treatment\"].unique()}')\n",
    "print(f'Start date: {sorted(phenotypic_data[\"timestamp\"])[0]}')\n",
    "print(f'End date: {sorted(phenotypic_data[\"timestamp\"])[-1]}')\n",
    "print(f'Samples: {phenotypic_data[\"Pot\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plotGenotypes(Experiment, Genotypes, hue=\"Genotype\"):\n",
    "  sns.lineplot(data=Experiment[Experiment['Genotype'].isin(Genotypes)], x=\"timestamp_hourly\", y=\"digital_biomass\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Plant digital biomass, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Genotype'].isin(Genotypes)], x=\"timestamp_hourly\", y=\"height\", hue=hue, palette=\"colorblind\")\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.title(\"Plant height, colored by {}\".format(hue))\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Genotype'].isin(Genotypes)], x=\"timestamp_hourly\", y=\"leaf_inclination\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Leaf inclination, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Genotype'].isin(Genotypes)], x=\"timestamp_hourly\", y=\"leaf_angle\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Leaf angle, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n",
    "def plotTreatment(Experiment, Treatment, hue=\"Pot\"):\n",
    "  sns.lineplot(data=Experiment[Experiment['Treatment'].isin(Treatment)], x=\"timestamp_hourly\", y=\"digital_biomass\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Plant digital biomass, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Treatment'].isin(Treatment)], x=\"timestamp_hourly\", y=\"height\", hue=hue, palette=\"colorblind\")\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.title(\"Plant height, colored by {}\".format(hue))\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Treatment'].isin(Treatment)], x=\"timestamp_hourly\", y=\"leaf_inclination\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Leaf inclination, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n",
    "  sns.lineplot(data=Experiment[Experiment['Treatment'].isin(Treatment)], x=\"timestamp_hourly\", y=\"leaf_angle\", hue=hue, palette=\"colorblind\")\n",
    "  plt.title(\"Leaf angle, colored by {}\".format(hue))\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plotTreatment(phenotypic_data, phenotypic_data[\"Treatment\"].unique(), hue=\"Pot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plotGenotypes(Experiment, Experiment[\"Genotype\"].unique(), hue=\"Treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram data\n",
    "\n",
    "Index options: greenness, ndvi, psri, hue and npci "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def get_histogram(index = \"greenness\", sample = None):\n",
    "    histogram_list = []\n",
    "    for assay in study.assays:\n",
    "        sample_name = assay.samples[0].name\n",
    "        timepoint = assay.filename\n",
    "        if sample != None and sample_name != sample:\n",
    "            break\n",
    "        for df in assay.data_files:\n",
    "            for com in df.comments:\n",
    "                if com.name == \"fullPath\" and \"_\" + index + \".csv\" in com.value:\n",
    "                    histogram_file =  \"./\" + com.value\n",
    "                    try:\n",
    "                        histogram_data = pandas.read_csv(histogram_file, sep=\";\")\n",
    "                        if len(histogram_list) > 0:\n",
    "                            histogram_data = histogram_data[histogram_data[\"sample\"] != \"edges\"]\n",
    "                        histogram_list.append(histogram_data) \n",
    "                    except Exception as e:\n",
    "                        print(\"Could not process histogram file: {}\".format(e))\n",
    "    histogram = pandas.concat(histogram_list, axis=0, ignore_index=True)\n",
    "    histogram[\"timepoint\"]= histogram[\"timepoint\"].apply(lambda x: dt.datetime.strptime(x, '%Y%m%dT%H%M%S'))\n",
    "    histogram[\"day\"] = histogram[\"timepoint\"].dt.date\n",
    "    # rename bin column names\n",
    "    xAxis = histogram[histogram[\"sample\"] == \"edges\"]\n",
    "    xAxis = xAxis.drop(columns=[\"day\", \"timepoint\", \"sample\"])\n",
    "    xAxis = xAxis.loc[0, :].values.flatten().tolist()\n",
    "    columns = {}\n",
    "    for c in range(0,257):\n",
    "        columns[\"bin{}\".format(c)] = xAxis[c]\n",
    "    histogram = histogram.rename(columns=columns)\n",
    "\n",
    "    return histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greenness plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sample_name = \"NPEC53.20250225.ID15.test.none.43\"\n",
    "sample = get_histogram(\"greenness\", sample_name)\n",
    "\n",
    "sample_melt = sample.melt(id_vars=[\"sample\", \"day\", \"timepoint\"])\n",
    "minDate = min(sample_melt[\"day\"])\n",
    "maxDate = max(sample_melt[\"day\"])\n",
    "\n",
    "#Normalize by total count for each day\n",
    "sample_melt['total_count'] = sample_melt.groupby('day')['value'].transform('sum')  # Total greenness values per day\n",
    "sample_melt['value_normalized'] = sample_melt['value'] / sample_melt['total_count']  # Normalize greenness\n",
    "\n",
    "# Plot the normalized values\n",
    "ax = sns.lineplot(data=sample_melt[(sample_melt[\"day\"] == minDate) | (sample_melt[\"day\"] == maxDate)],\n",
    "                  x=\"variable\", y=\"value_normalized\", hue=\"day\")\n",
    "#ax = sns.lineplot(data = sample_melt[(sample_melt[\"day\"] == minDate) | (sample_melt[\"day\"] == maxDate)], x=\"variable\", y=\"value\", hue=\"day\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Greenness for {}\".format(sample_name))\n",
    "plt.xlabel(\"Greenness\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vigor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sample to calculate vigor for\n",
    "sample = \"NPEC53.20250225.ID15.test.none.43\"\n",
    "\n",
    "# Filter data for the specific sample and sort by 'timestamp'\n",
    "vigor = phenotypic_data[phenotypic_data['Pot'] == sample].sort_values(by=['Pot', 'timestamp'])\n",
    "\n",
    "# Define the time interval for interpolation (e.g., every 1 hour)\n",
    "resample_interval = '12h'  # or '6H', '12H', etc. depending on the desired frequency\n",
    "\n",
    "# Function to interpolate biomass for a single sample\n",
    "def interpolate_biomass(df):\n",
    "    # Set 'timestamp' as the index to allow resampling\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    # Resample biomass at the defined interval and interpolate missing values\n",
    "    resampled_df = df[['digital_biomass']].resample(resample_interval).mean()  # Resample every X hours\n",
    "\n",
    "    # Interpolate only the 'digital_biomass' column\n",
    "    resampled_df['digital_biomass'] = resampled_df['digital_biomass'].interpolate(method='polynomial', order=3)\n",
    "    resampled_df['digital_biomass'] = resampled_df['digital_biomass'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "    # Forward fill 'Pot' (non-numeric column)\n",
    "    resampled_df['Pot'] = df['Pot'].ffill()\n",
    "\n",
    "    # Reset index to return to the original structure\n",
    "    return resampled_df.reset_index()\n",
    "\n",
    "# Directly apply interpolation without using apply() (since we're working with a single sample)\n",
    "df_interpolated = interpolate_biomass(vigor)\n",
    "\n",
    "# Calculate the time difference (in hours) between consecutive time points\n",
    "df_interpolated['time_change'] = df_interpolated['timestamp'].diff().dt.total_seconds() / 3600.0\n",
    "\n",
    "# Calculate the biomass change\n",
    "df_interpolated['biomass_change'] = df_interpolated['digital_biomass'].diff()\n",
    "df_interpolated['biomass_change'] = df_interpolated['biomass_change'].interpolate(method='polynomial', order=3)\n",
    "df_interpolated['biomass_change'] = df_interpolated['biomass_change'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Calculate vigor (biomass change per hour)\n",
    "df_interpolated['vigor'] = df_interpolated['biomass_change'] / df_interpolated['time_change']\n",
    "\n",
    "# Drop NaN values created by diff() in the first row\n",
    "df_interpolated = df_interpolated.dropna(subset=['time_change', 'biomass_change'])\n",
    "\n",
    "# Plot the vigor over time for the sample\n",
    "plt.plot(df_interpolated['timestamp'], df_interpolated['vigor'], label=sample)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Vigor (digital biomass change per hour)')\n",
    "plt.title(f'Vigor Over Time for Sample {sample}')\n",
    "plt.legend(title='Sample')\n",
    "plt.show()\n",
    "\n",
    "# Plot the biomass over time for the sample\n",
    "plt.plot(df_interpolated['timestamp'], df_interpolated['digital_biomass'], label=sample)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Digital biomass')\n",
    "plt.title(f'Digital biomass over time {sample}')\n",
    "plt.legend(title='Sample')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
