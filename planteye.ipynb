{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PlantEye F500 Technology Overview\n",
    "\n",
    "The **PlantEye F500** is an advanced 3D multispectral plant scanner developed by Phenospex. It is designed to capture detailed morphological and physiological data from plants in a non-invasive, high-throughput manner. This technology is widely used in plant phenotyping, agriculture research, and precision farming.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **3D Laser Scanning**: The F500 uses laser triangulation to generate accurate 3D point clouds of plant canopies. This allows for detailed measurements of plant structure, including height, leaf area, and volume.\n",
    "\n",
    "- **Multispectral Imaging**: The device integrates multispectral sensors that capture reflectance in several wavelengths (typically Red, Green, Blue, and Near-Infrared). This enables the calculation of vegetation indices such as NDVI, and NPCI.\n",
    "\n",
    "- **High Throughput**: The F500 can scan large numbers of plants quickly, making it suitable for field-based phenotyping and automated greenhouse systems.\n",
    "\n",
    "- **Environmental Adaptability**: Designed for both controlled environments (greenhouses, growth chambers) and outdoor use, the scanner compensates for variable lighting conditions and can operate under various weather scenarios.\n",
    "\n",
    "- **Data Integration**: PlantEye F500 data is typically output in 3D point clouds and .csv formats, which include spatial coordinates (x, y, z), spectral values (R, G, B, NIR), and derived indices. This makes it compatible with a wide range of data analysis tools and programming environments.\n",
    "\n",
    "## Output Data\n",
    "\n",
    "The F500 generates comprehensive datasets that can be used for scientific research and agricultural decision-making. Each scan typically includes:\n",
    "\n",
    "- 3D point cloud data (x, y, z)\n",
    "- Spectral reflectance values (R, G, B, NIR)\n",
    "- Vegetation indices (e.g., NDVI, NPCI)\n",
    "- Derived traits such as plant height, projected leaf area, and volume\n",
    "\n",
    "## Data Processing at NPEC\n",
    "\n",
    "The **Netherlands Plant Eco-phenotyping Centre (NPEC)** utilizes open-source software tools to process and analyze data generated by the PlantEye F500. These tools focus on extracting meaningful biological insights from the rich 3D point cloud data and associated multispectral measurements.\n",
    "\n",
    "### Index Calculation and Histograms\n",
    "\n",
    "NPEC's data pipeline includes software that computes various **vegetation indices** from the 3D point clouds. These indices—such as NDVI (Normalized Difference Vegetation Index) and NPCI (Normalized Pigment Chlorophyll Index)—provide quantitative indicators of plant health, biomass, and physiological status.\n",
    "\n",
    "Additionally, **histograms** are generated to represent the distribution of these indices across the scanned plant area. These visualizations help in identifying variations and patterns in plant traits, and they serve as useful diagnostic tools for phenotyping.\n",
    "\n",
    "### Metadata Management with ISA-JSON\n",
    "\n",
    "To ensure reproducibility and semantic interoperability, all experimental metadata is stored using the **ISA-JSON** format. ISA (Investigation-Study-Assay) is a standardized metadata framework widely adopted in life sciences. In this context, the ISA-JSON files contain crucial information about:\n",
    "\n",
    "- The experiment setup\n",
    "- Plant and treatment details\n",
    "- Links to raw and processed data\n",
    "\n",
    "These metadata files will be used within this notebook to **load, visualize, and analyze** the corresponding datasets. This integration ensures that each analysis step is traceable and properly contextualized with respect to the original experimental design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please set `threshold_date` to the start of the experiment. In some case there were trial measurements which you don't need to use your analysis.\n",
    "\n",
    "### 🧪 **Overview of the Code Block**\n",
    "\n",
    "This part of the notebook sets up the tools and data needed for analyzing a plant phenotyping experiment. It prepares the environment to read both the measurements and the metadata collected during the experiment.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 **What Each Section Does**\n",
    "\n",
    "#### 1. **Importing Tools (Libraries)**\n",
    "\n",
    "```python\n",
    "import ...\n",
    "```\n",
    "\n",
    "This section loads Python *libraries*, which are like toolboxes. Each one has a specific purpose:\n",
    "\n",
    "* `json`, `os`: For handling files and data formats.\n",
    "* `isatools`: For working with ISA-JSON metadata files, which store experimental descriptions.\n",
    "* `pandas`, `numpy`: For organizing and processing tables of data (like spreadsheets).\n",
    "* `matplotlib`, `seaborn`: For making charts and graphs.\n",
    "* `datetime`, `PIL`: For working with dates and images.\n",
    "\n",
    "You don't need to know the details of each, but think of them as helpers to handle different parts of your data and analysis.\n",
    "\n",
    "#### 2. **Specifying Where the Data Lives**\n",
    "\n",
    "```python\n",
    "isa_json = \"...json\"\n",
    "metadata_file = \"...csv\"\n",
    "data_folder = \"...\"\n",
    "threshold_date = ...\n",
    "```\n",
    "\n",
    "This section defines the *paths* (locations on your computer or server) where the files are stored:\n",
    "\n",
    "* `isa_json`: The main **metadata file** (in ISA-JSON format) that describes your experiment.\n",
    "* `metadata_file`: A **CSV file** that includes plant-level information, like pot IDs or treatments.\n",
    "* `data_folder`: The general folder where data files are stored.\n",
    "* `threshold_date`: A specific date used later, possibly to filter out older data.\n",
    "\n",
    "#### 3. **Loading the Experiment Metadata**\n",
    "\n",
    "```python\n",
    "investigation = isajson.load(open(isa_json, \"r\"))\n",
    "study = investigation.studies[0]\n",
    "```\n",
    "\n",
    "This reads the ISA-JSON file and pulls out the *first study* described in the experiment. This metadata includes information like treatments, instruments used, and timing.\n",
    "\n",
    "#### 4. **Reading the Plant Metadata Table**\n",
    "\n",
    "```python\n",
    "metadata = pd.read_csv(metadata_file, delimiter = \";\", engine = \"python\")\n",
    "```\n",
    "\n",
    "This reads the CSV file into a table (called a *DataFrame* in Python) so that it can be used in analysis.\n",
    "\n",
    "#### 5. **Tidying Up the Table**\n",
    "\n",
    "```python\n",
    "metadata[['Pot']] = metadata['DataMatrix'].str.split(\" \", expand=True)\n",
    "metadata = metadata.drop('DataMatrix', axis=1)\n",
    "```\n",
    "\n",
    "These lines clean up the metadata table:\n",
    "\n",
    "* They split one column (`DataMatrix`) into separate parts to isolate the `Pot` ID.\n",
    "* Then they remove the original `DataMatrix` column since it's no longer needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **Why This Matters**\n",
    "\n",
    "This setup ensures:\n",
    "\n",
    "* You can link measurement data with the correct experimental treatments.\n",
    "* You have clear and clean metadata, ready to be used for analysis and visualization.\n",
    "* Everything is traceable, thanks to the structured ISA-JSON format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "from isatools.isajson import ISAJSONEncoder\n",
    "import isatools\n",
    "from isatools.model import *\n",
    "from isatools import isajson\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "root_folder = \"W:/PROJECTS/NPEC_greenhouse/f500/project_output_full/azure/gantry3/\"\n",
    "isa_json = f\"{root_folder}NPEC_Potdata_Gantry3_exp41_running.csv.json\"\n",
    "metadata_file = f\"{root_folder}running_exp41_Gantry3/exp41/metadata/NPEC_Potdata_Gantry3_exp41_running.csv\"\n",
    "data_folder = f\"{root_folder}\"\n",
    "threshold_date = dt.datetime(2025, 6, 19)\n",
    "\"\"\"\n",
    "gantry = 3\n",
    "exp_id = 41\n",
    "root_folder = f\"W:/PROJECTS/NPEC_greenhouse/f500/project_output_full/azure/gantry{gantry}/\"\n",
    "isa_json = f\"{root_folder}NPEC_Potdata_Gantry{gantry}_exp{exp_id}_running.csv.json\"\n",
    "metadata_file = f\"{root_folder}running_exp{exp_id}_Gantry{gantry}/exp{exp_id}/metadata/NPEC_Potdata_Gantry{gantry}_exp{exp_id}_running.csv\"\n",
    "data_folder = f\"{root_folder}\"\n",
    "\n",
    "threshold_date = dt.datetime(2025, 7, 1)\n",
    "\n",
    "\n",
    "\n",
    "investigation = isajson.load(open(isa_json, \"r\"))\n",
    "study = investigation.studies[0]\n",
    "\n",
    "metadata = pd.read_csv(metadata_file, delimiter = \";\", engine = \"python\")\n",
    "metadata[['Pot']] = metadata['DataMatrix'].str.split(\" \", expand=True)\n",
    "metadata = metadata.drop('DataMatrix', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotypic data\n",
    "\n",
    "### 🧬 **What This Code Does: Reading Phenotypic Data**\n",
    "\n",
    "```python\n",
    "phenotypic_data_list = []\n",
    "```\n",
    "\n",
    "This creates an empty list to store the phenotypic data tables as they are read from files.\n",
    "\n",
    "#### 🔁 Looping Through the Assays\n",
    "\n",
    "```python\n",
    "for assay in study.assays:\n",
    "```\n",
    "\n",
    "This goes through each **assay** in your study. In ISA metadata, an \"assay\" typically refers to one measurement activity—like scanning plants on a specific date.\n",
    "\n",
    "##### Getting Sample Info\n",
    "\n",
    "```python\n",
    "    sample_name = assay.samples[0].name\n",
    "    timepoint = assay.filename\n",
    "    title = assay.filename\n",
    "```\n",
    "\n",
    "These lines pull out information about the assay:\n",
    "\n",
    "* `sample_name`: the name of the sample being measured.\n",
    "* `timepoint` and `title`: here, both are based on the filename, which likely encodes the date or condition of the scan.\n",
    "\n",
    "##### Looping Through Data Files\n",
    "\n",
    "```python\n",
    "    for df in assay.data_files:\n",
    "        for com in df.comments:\n",
    "            if com.name == \"fullPath\" and \"/\" + title + \".csv\" in com.value:\n",
    "```\n",
    "\n",
    "Each assay can have multiple files. This loop:\n",
    "\n",
    "* Looks through each file linked to the assay.\n",
    "* Checks the **comments** attached to the file to find the one that contains the full path to the relevant CSV file with phenotypic data.\n",
    "* It matches based on the title (e.g., `\"scan_2021-04-01.csv\"`).\n",
    "\n",
    "##### Reading and Storing Data\n",
    "\n",
    "```python\n",
    "                assay_data = pd.read_csv(data_folder + com.value, header=0, delimiter=\";\")\n",
    "                phenotypic_data_list.append(assay_data)\n",
    "```\n",
    "\n",
    "Once it finds the correct file, it:\n",
    "\n",
    "* Reads it into a **dataframe** (like a spreadsheet in Python).\n",
    "* Appends it to the list of all assay data.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **Combining and Merging the Data**\n",
    "\n",
    "```python\n",
    "phenotypic_data = pd.concat(phenotypic_data_list, axis=0, ignore_index=True)\n",
    "```\n",
    "\n",
    "This stacks all the data from each assay into **one large table**. It resets the row numbers to keep things clean.\n",
    "\n",
    "```python\n",
    "phenotypic_data = pd.merge(phenotypic_data, metadata, on='Pot')\n",
    "```\n",
    "\n",
    "Finally, it **merges** the phenotypic data with the earlier metadata table using the `Pot` ID. This means each measurement will now include information like plant variety, treatment, and position—essential context for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌿 **Why This Is Important**\n",
    "\n",
    "* It **automatically finds and reads** all relevant measurement files.\n",
    "* It organizes the data into one unified table that’s ready for analysis.\n",
    "* It connects each measurement to its biological context (via metadata).\n",
    "* It follows best practices for reproducibility by relying on the metadata defined in the ISA-JSON structure.\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 Summary for Plant Researchers\n",
    "\n",
    "This part of the notebook pulls together **all trait measurements** (like height, leaf area, indices) taken during the experiment. It reads the data from individual files for each scanning session and combines them into one complete dataset. Then it enriches that data with information about each plant’s identity and treatment. This makes it ready for visualization, statistical analysis, or export.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypic_data_list = []\n",
    "for assay in study.assays:\n",
    "    sample_name = assay.samples[0].name\n",
    "    timepoint = assay.filename\n",
    "    title = assay.filename\n",
    "\n",
    "    for df in assay.data_files:\n",
    "        for com in df.comments:\n",
    "            if com.name == \"fullPath\" and \"/\" + title + \".csv\" in com.value:\n",
    "                try:\n",
    "                    assay_data = pd.read_csv(data_folder + com.value, header=0, delimiter=\";\")\n",
    "                    phenotypic_data_list.append(assay_data)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "phenotypic_data = pd.concat(phenotypic_data_list, axis=0, ignore_index=True)\n",
    "\n",
    "phenotypic_data = pd.merge(phenotypic_data, metadata, on='Pot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting data\n",
    "\n",
    "### 🧼 **Cleaning and Formatting the Phenotypic Data**\n",
    "\n",
    "Once the phenotypic measurements have been loaded, they often require additional formatting before they can be used in analysis. This code block prepares the dataset by correcting timestamps, filtering by date, and creating useful new columns.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 **Explanation of Each Step**\n",
    "\n",
    "#### 🔧 1. **Creating a Combined Column**\n",
    "\n",
    "```python\n",
    "def concatenate_columns(row, x, y):\n",
    "    return f\"{row[x]}, {row[y]}\"\n",
    "```\n",
    "\n",
    "This defines a small helper function. It takes a row of data and joins the values from two columns (like `Treatment` and `Genotype`) into one string, separated by a comma. For example:\n",
    "\n",
    "```\n",
    "\"Control, Wild-type\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔄 2. **Fixing Column Names After Merge**\n",
    "\n",
    "```python\n",
    "phenotypic_data[\"Treatment\"] = phenotypic_data[\"Treatment_y\"]\n",
    "```\n",
    "\n",
    "After merging the phenotypic data with the metadata, there may be multiple `Treatment` columns. This line picks the correct one (`Treatment_y`) and standardizes its name to just `Treatment`.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🕒 3. **Parsing the Timestamps**\n",
    "\n",
    "```python\n",
    "phenotypic_data[\"timestamp\"]= phenotypic_data[\"timestamp\"].apply(lambda x: dt.datetime.strptime(x, '%Y%m%dT%H%M%S'))\n",
    "```\n",
    "\n",
    "The original timestamps (recorded as plain text like `20210421T093015`) are converted into proper Python **datetime** objects. This allows for accurate filtering and time-based analysis later.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📅 4. **Extracting Date and Hour**\n",
    "\n",
    "```python\n",
    "phenotypic_data[\"day\"] = phenotypic_data[\"timestamp\"].dt.date\n",
    "phenotypic_data['timestamp_hourly'] = phenotypic_data['timestamp'].dt.floor('h')\n",
    "```\n",
    "\n",
    "These two lines:\n",
    "\n",
    "* Extract just the **calendar date** (used to group measurements by day).\n",
    "* Round the timestamp down to the **nearest full hour**, which is useful for summarizing data collected at different moments.\n",
    "\n",
    "---\n",
    "\n",
    "#### ⏳ 5. **Filtering by a Start Date**\n",
    "\n",
    "```python\n",
    "phenotypic_data = phenotypic_data[phenotypic_data[\"timestamp\"] >= threshold_date]\n",
    "```\n",
    "\n",
    "This removes any measurements that were taken before a specified start date (`threshold_date`), likely to focus the analysis on a specific experimental window.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧬 6. **Creating a Composite Label**\n",
    "\n",
    "```python\n",
    "phenotypic_data[\"Treatment, genotype\"] =  phenotypic_data.apply(concatenate_columns, axis=1, x='Treatment', y='Genotype')\n",
    "```\n",
    "\n",
    "This uses the earlier helper function to create a new column called `\"Treatment, genotype\"`, which combines both pieces of information into a single label. This is useful for grouping or coloring plots later on.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Why This Matters**\n",
    "\n",
    "* Makes **time information usable** for analysis (by converting to datetime).\n",
    "* Prepares the data for **time-series plots**, daily summaries, and condition-based grouping.\n",
    "* Ensures that the data reflects only the **relevant experimental period**.\n",
    "* Simplifies visualization and statistical grouping with a combined treatment/genotype label.\n",
    "\n",
    "---\n",
    "\n",
    "### 👩‍🔬 Summary for Researchers\n",
    "\n",
    "This step cleans up the dataset by formatting time data, removing older entries, and creating combined labels for easier grouping in plots and analyses. It's a crucial part of making raw measurement data ready for meaningful biological interpretation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_columns(row, x, y):\n",
    "    return f\"{row[x]}, {row[y]}\"\n",
    "\n",
    "if gantry == 4 and exp_id == 40:\n",
    "    phenotypic_data[\"Treatment_y\"] = \"Normal\"\n",
    "    phenotypic_data[\"Genotype\"] = \"Tree\"\n",
    "\n",
    "phenotypic_data[\"Treatment\"] = phenotypic_data[\"Treatment_y\"]\n",
    "phenotypic_data[\"timestamp\"]= phenotypic_data[\"timestamp\"].apply(lambda x: dt.datetime.strptime(x, '%Y%m%dT%H%M%S'))\n",
    "phenotypic_data[\"day\"] = phenotypic_data[\"timestamp\"].dt.date\n",
    "phenotypic_data['timestamp_hourly'] = phenotypic_data['timestamp'].dt.floor('h')\n",
    "phenotypic_data = phenotypic_data[phenotypic_data[\"timestamp\"] >= threshold_date]\n",
    "\n",
    "phenotypic_data[\"Treatment, genotype\"] =  phenotypic_data.apply(concatenate_columns, axis=1, x='Treatment', y='Genotype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### 📋 **Summary of Phenotypic Dataset**\n",
    "\n",
    "This code block provides a clean, readable summary of the dataset you’ve just prepared. It's designed to help researchers quickly understand the scope and content of their phenotypic data before deeper analysis or visualization.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧾 **What the Code Does**\n",
    "\n",
    "#### 1. **Imports a Display Tool**\n",
    "\n",
    "```python\n",
    "from IPython.display import display, Markdown\n",
    "```\n",
    "\n",
    "This allows the notebook to show output in **Markdown format**, which makes it easier to read than plain text.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Calculates Key Statistics**\n",
    "\n",
    "```python\n",
    "num_data_points = len(phenotypic_data[\"timestamp\"])\n",
    "genotypes = phenotypic_data[\"Genotype\"].unique()\n",
    "num_genotypes = len(genotypes)\n",
    "max_height = phenotypic_data[\"height_max\"].dropna().max()\n",
    "min_max_height = phenotypic_data[\"height_max\"].dropna().min()\n",
    "avg_max_height = phenotypic_data[\"height_max\"].dropna().mean()\n",
    "treatments = phenotypic_data[\"Treatment\"].unique()\n",
    "start_date = phenotypic_data[\"timestamp\"].min()\n",
    "end_date = phenotypic_data[\"timestamp\"].max()\n",
    "samples = phenotypic_data[\"Pot\"].unique()\n",
    "```\n",
    "\n",
    "This section gathers various summary statistics:\n",
    "\n",
    "* Number of individual measurements\n",
    "* List and count of different **genotypes**\n",
    "* Maximum, minimum, and average of **maximum plant heights**\n",
    "* List of all **treatments**\n",
    "* Start and end date of the experiment (based on timestamps)\n",
    "* List of unique **pots** (samples)\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Creates a User-Friendly Summary**\n",
    "\n",
    "```python\n",
    "summary_text = f\"\"\"...\"\"\"\n",
    "display(Markdown(summary_text))\n",
    "```\n",
    "\n",
    "Here, the summary is formatted as a human-readable block using Markdown. This makes it easier to read in a notebook and more suitable for reports or sharing with collaborators.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **Why This Is Useful for Researchers**\n",
    "\n",
    "* Gives a **quick overview** of the experimental dataset.\n",
    "* Helps **verify** that the data has been read and interpreted correctly.\n",
    "* Allows researchers to **spot potential issues early** (e.g., missing height data, unexpected dates).\n",
    "* Provides **context** for more detailed plots and statistical analyses.\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 Example Output\n",
    "\n",
    "```\n",
    "🌿 Phenotypic Dataset Summary\n",
    "\n",
    "- Total number of measurements: 1248\n",
    "- Number of unique genotypes: 6\n",
    "- List of genotypes: WT, Mut1, Mut2, ...\n",
    "- Maximum recorded plant height: 412.67 mm\n",
    "- Minimum of maximum plant heights: 58.00 mm\n",
    "- Average of maximum plant heights: 193.46 mm\n",
    "- Treatments applied: Control, Drought\n",
    "- Measurement period: From 2021-04-01 09:00 to 2021-04-15 18:00\n",
    "- Number of unique pots (samples): 72\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Gather values\n",
    "num_data_points = len(phenotypic_data[\"timestamp\"])\n",
    "genotypes = phenotypic_data[\"Genotype\"].unique()\n",
    "num_genotypes = len(genotypes)\n",
    "max_height = phenotypic_data[\"height_max\"].dropna().max()\n",
    "min_max_height = phenotypic_data[\"height_max\"].dropna().min()\n",
    "avg_max_height = phenotypic_data[\"height_max\"].dropna().mean()\n",
    "treatments = phenotypic_data[\"Treatment\"].unique()\n",
    "start_date = phenotypic_data[\"timestamp\"].min()\n",
    "end_date = phenotypic_data[\"timestamp\"].max()\n",
    "samples = phenotypic_data[\"Pot\"].unique()\n",
    "\n",
    "# Display formatted summary\n",
    "summary_text = f\"\"\"\n",
    "### 🌿 Phenotypic Dataset Summary\n",
    "\n",
    "- **Total number of measurements:** {num_data_points}\n",
    "- **Number of unique genotypes:** {num_genotypes}\n",
    "- **List of genotypes:** {', '.join(genotypes)}\n",
    "- **Maximum recorded plant height:** {max_height:.2f} mm\n",
    "- **Minimum of maximum plant heights:** {min_max_height:.2f} mm\n",
    "- **Average of maximum plant heights:** {avg_max_height:.2f} mm\n",
    "- **Treatments applied:** {', '.join(treatments)}\n",
    "- **Measurement period:** From **{start_date.strftime('%Y-%m-%d %H:%M')}** to **{end_date.strftime('%Y-%m-%d %H:%M')}**\n",
    "- **Number of unique pots (samples):** {len(samples)}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌿 **Explanation of Measured Traits from PlantEye F500**\n",
    "\n",
    "The **PlantEye F500** uses 3D laser scanning and multispectral imaging to non-destructively assess various morphological and physiological traits of plants. The following traits are derived from the **3D point clouds** generated during each scan:\n",
    "\n",
    "---\n",
    "\n",
    "### 📏 **1. Height (`height`)**\n",
    "\n",
    "* **What it is:** The vertical distance from the ground to the highest point of the plant canopy.\n",
    "* **How it's measured:** Calculated directly from the 3D point cloud by identifying the highest z-coordinate in the plant's scanned area.\n",
    "* **Why it's useful:** A primary indicator of plant growth over time and response to environmental conditions or treatments.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **2. Digital Biomass (`digital_biomass`)**\n",
    "\n",
    "* **What it is:** An estimate of plant biomass based on the volume and density of the 3D point cloud.\n",
    "* **How it's measured:** Derived using the number and distribution of 3D points that represent the plant. It often correlates with actual biomass measured destructively.\n",
    "* **Why it's useful:** Provides a non-destructive approximation of total plant growth, which is crucial for longitudinal studies and high-throughput phenotyping.\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 **3. Leaf Inclination (`leaf_inclination`)**\n",
    "\n",
    "* **What it is:** The average **tilt angle** of the leaves relative to the vertical axis.\n",
    "* **How it's measured:** Calculated using the orientation of 3D surface normals in the point cloud, which indicate how steeply the leaves are angled upward or outward.\n",
    "* **Why it's useful:** Reflects the plant's light interception strategy. More upright leaves can indicate different photosynthetic or stress-adaptive behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 **4. Leaf Angle (`leaf_angle`)**\n",
    "\n",
    "* **What it is:** Often refers to the angle between a leaf surface and the horizontal plane.\n",
    "* **How it's measured:** Similar to leaf inclination, but this metric may average angles more broadly across the canopy or use a different reference axis.\n",
    "* **Why it's useful:** A sensitive indicator of plant response to environmental stresses (e.g., drought or light competition), as leaf posture can change in reaction to water availability or light direction.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 **Why These Traits Matter**\n",
    "\n",
    "These measurements together provide a **multi-dimensional view of plant growth**:\n",
    "\n",
    "* **Height and digital biomass** tell you about **size and structural development**.\n",
    "* **Leaf inclination and angle** tell you about **architecture and physiological responses**.\n",
    "\n",
    "All are captured automatically and non-destructively by the PlantEye F500, enabling repeated measurements over time with high throughput.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting functions\n",
    "\n",
    "### 📈 **Visualization Functions for Phenotypic Traits**\n",
    "\n",
    "These two functions—`plotGenotypes()` and `plotTreatment()`—are designed to help researchers visualize how key plant traits evolve over time, grouped either by **genotype** or **treatment**.\n",
    "\n",
    "Each plot shows one trait over time (using hourly timestamps), with lines grouped by individual plants, genotypes, or treatments.\n",
    "\n",
    "---\n",
    "\n",
    "## 🌿 `plotGenotypes()`\n",
    "\n",
    "### 🔧 **Function Purpose**\n",
    "\n",
    "This function generates **line plots** of selected traits for one or more genotypes, over time. It allows comparison between different genotypes within the experiment.\n",
    "\n",
    "### 📥 **Inputs**\n",
    "\n",
    "* `Experiment`: the full phenotypic dataset (a DataFrame).\n",
    "* `Genotypes`: a list of genotype names to plot (e.g., `[\"WT\", \"Mut1\"]`).\n",
    "* `hue`: determines what variable is used to color the lines (default is `\"Genotype\"`).\n",
    "\n",
    "### 📊 **Traits Plotted**\n",
    "\n",
    "* `digital_biomass`\n",
    "* `height`\n",
    "* `leaf_inclination`\n",
    "* `leaf_angle`\n",
    "\n",
    "### 📌 **How It Works**\n",
    "\n",
    "1. Filters the dataset to include only the selected genotypes.\n",
    "2. For each trait:\n",
    "\n",
    "   * Draws a line plot with time on the x-axis and the trait on the y-axis.\n",
    "   * Colors the lines by the `hue` variable (e.g., genotype or individual plant).\n",
    "3. Displays each trait in a separate plot.\n",
    "\n",
    "### 🖼️ **Example Use**\n",
    "\n",
    "```python\n",
    "plotGenotypes(phenotypic_data, [\"WT\", \"Mut1\"])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🌱 `plotTreatment()`\n",
    "\n",
    "### 🔧 **Function Purpose**\n",
    "\n",
    "This function visualizes plant traits over time, grouped by treatment (e.g., `\"Control\"` vs `\"Drought\"`). It helps researchers observe how treatments affect plant development.\n",
    "\n",
    "### 📥 **Inputs**\n",
    "\n",
    "* `Experiment`: the phenotypic dataset.\n",
    "* `Treatment`: a list of treatment names to include in the plots.\n",
    "* `hue`: determines what variable is used to color the lines (default is `\"Pot\"` to see each plant individually).\n",
    "\n",
    "### 📊 **Traits Plotted**\n",
    "\n",
    "Same as above:\n",
    "\n",
    "* `digital_biomass`\n",
    "* `height`\n",
    "* `leaf_inclination`\n",
    "* `leaf_angle`\n",
    "\n",
    "### 📌 **How It Works**\n",
    "\n",
    "1. Filters the data to only include the selected treatments.\n",
    "2. Plots each trait over time, coloring lines by the selected `hue` (default is individual plant).\n",
    "3. Rotates x-axis labels for better readability.\n",
    "\n",
    "### 🖼️ **Example Use**\n",
    "\n",
    "```python\n",
    "plotTreatment(phenotypic_data, [\"Control\", \"Drought\"])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Why These Functions Matter**\n",
    "\n",
    "* Enable quick **visual inspection** of how plant traits vary across genotypes or treatments.\n",
    "* Facilitate **exploratory data analysis** before running statistical tests.\n",
    "* Offer **customizable groupings** through the `hue` argument (e.g., color by genotype, pot, or treatment).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGenotypes(Experiment, Genotypes, hue=\"Genotype\", legend=True):\n",
    "    Genotypes = list(Genotypes)\n",
    "\n",
    "    traits = [\"digital_biomass\", \"height\", \"leaf_inclination\", \"leaf_angle\"]\n",
    "    filtered = Experiment[Experiment['Genotype'].isin(Genotypes)]\n",
    "\n",
    "    for trait in traits:\n",
    "        sns.lineplot(\n",
    "            data=filtered,\n",
    "            x=\"timestamp_hourly\",\n",
    "            y=trait,\n",
    "            hue=hue,\n",
    "            palette=\"colorblind\"\n",
    "        )\n",
    "        plt.title(f\"Plant {trait.replace('_', ' ')}, colored by {hue}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        if legend:\n",
    "            plt.legend(title=hue)\n",
    "        else:\n",
    "            plt.legend().remove()\n",
    "        plt.show()\n",
    "\n",
    "def plotGenotypePanel(Experiment, Genotypes, hue=\"Genotype\", legend=True, traits = [\"digital_biomass\", \"height\", \"leaf_inclination\", \"leaf_angle\"]):\n",
    "    Genotypes = list(Genotypes)\n",
    "\n",
    "    filtered = Experiment[Experiment['Genotype'].isin(Genotypes)]\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(Genotypes),\n",
    "        ncols=len(traits),\n",
    "        figsize=(5 * len(traits), 4 * len(Genotypes)),\n",
    "        sharex=True,\n",
    "        sharey='col'\n",
    "    )\n",
    "\n",
    "    if len(Genotypes) == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "    if len(traits) == 1:\n",
    "        axes = np.expand_dims(axes, axis=1)\n",
    "\n",
    "    for row_idx, genotype in enumerate(Genotypes):\n",
    "        genotype_data = filtered[filtered['Genotype'] == genotype]\n",
    "        for col_idx, trait in enumerate(traits):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            sns.lineplot(\n",
    "                data=genotype_data,\n",
    "                x=\"timestamp_hourly\",\n",
    "                y=trait,\n",
    "                hue=hue,\n",
    "                palette=\"colorblind\",\n",
    "                ax=ax,\n",
    "                legend=False\n",
    "            )\n",
    "            if row_idx == 0:\n",
    "                ax.set_title(f\"{trait.replace('_', ' ')}\")\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(genotype)\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    if legend:\n",
    "        handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "        fig.legend(handles, labels, title=hue, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotTreatment(Experiment, Treatment, hue=\"Pot\", legend=True):\n",
    "    Treatment = list(Treatment)  # ensure it's 1D\n",
    "\n",
    "    for trait in [\"digital_biomass\", \"height\", \"leaf_inclination\", \"leaf_angle\"]:\n",
    "        sns.lineplot(\n",
    "            data=Experiment[Experiment['Treatment'].isin(Treatment)],\n",
    "            x=\"timestamp_hourly\",\n",
    "            y=trait,\n",
    "            hue=hue,\n",
    "            palette=\"colorblind\"\n",
    "        )\n",
    "        plt.title(f\"Plant {trait.replace('_', ' ')}, colored by {hue}\")\n",
    "        plt.xticks(rotation=90)\n",
    "        if legend:\n",
    "            plt.legend(title=hue)\n",
    "        else:\n",
    "            plt.legend().remove()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot traits grouped by treatment\n",
    "\n",
    "```python\n",
    "plotTreatment(phenotypic_data, phenotypic_data[\"Treatment\"].unique(), hue=\"Pot\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **What This Call Does**\n",
    "\n",
    "This line of code uses the `plotTreatment()` function to **visualize plant traits over time**, grouped by **treatment** and colored by **individual pots** (i.e., each plant).\n",
    "\n",
    "---\n",
    "\n",
    "### 📥 **Arguments Explained**\n",
    "\n",
    "* `phenotypic_data`: This is your cleaned dataset that contains all the measured traits, timestamps, metadata, and more.\n",
    "\n",
    "* `phenotypic_data[\"Treatment\"].unique()`: This dynamically gets a list of all **treatment conditions** in your dataset (e.g., `[\"Control\", \"Drought\"]`), ensuring that **every treatment** in the experiment is included in the plots.\n",
    "\n",
    "* `hue=\"Pot\"`: This tells the plotting function to color each line by the **individual plant pot**. This allows you to see how **each specific plant** responded under its treatment.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **What You'll See**\n",
    "\n",
    "For each of the following traits:\n",
    "\n",
    "* `digital_biomass`\n",
    "* `height`\n",
    "* `leaf_inclination`\n",
    "* `leaf_angle`\n",
    "\n",
    "You'll get a **line plot** where:\n",
    "\n",
    "* The x-axis shows time (`timestamp_hourly`)\n",
    "* The y-axis shows the trait value\n",
    "* Each line represents a **different plant**\n",
    "* The color identifies which plant (pot) it is\n",
    "* The title indicates which trait is being plotted and that it's colored by `\"Pot\"`\n",
    "\n",
    "Each trait is shown in a **separate plot**, and all treatments are included side by side.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 **Why Use This**\n",
    "\n",
    "* Allows you to **visually compare** how individual plants responded to different treatments.\n",
    "* Helps detect **outliers**, inconsistencies, or trends in how specific traits changed over time.\n",
    "* Offers insights into **plant variability** within treatments—key for understanding treatment effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTreatment(phenotypic_data, phenotypic_data[\"Treatment\"].unique(), hue=\"Pot\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot traits grouped by genotype\n",
    "\n",
    "```python\n",
    "plotGenotypes(phenotypic_data, phenotypic_data[\"Genotype\"].unique(), hue=\"Treatment\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **What This Call Does**\n",
    "\n",
    "This line visualizes how plant traits change over time **for all genotypes**, with each line **colored by treatment**.\n",
    "\n",
    "---\n",
    "\n",
    "### 📥 **Arguments Explained**\n",
    "\n",
    "* `phenotypic_data`: The full dataset containing measurements, timestamps, genotypes, treatments, and calculated traits.\n",
    "\n",
    "* `phenotypic_data[\"Genotype\"].unique()`: This automatically collects all **distinct genotypes** in the dataset (e.g., `[\"WT\", \"Mut1\", \"Mut2\"]`). It ensures that **every genotype** in the study is included in the visualization.\n",
    "\n",
    "* `hue=\"Treatment\"`: Instead of coloring lines by genotype or pot, this colors them by **treatment condition** (e.g., `\"Control\"` or `\"Drought\"`). This lets you easily compare how treatments affect plants **within each genotype**.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **What You'll See**\n",
    "\n",
    "For each of the following traits:\n",
    "\n",
    "* `digital_biomass`\n",
    "* `height`\n",
    "* `leaf_inclination`\n",
    "* `leaf_angle`\n",
    "\n",
    "You will get a separate **line plot** where:\n",
    "\n",
    "* The x-axis shows the time (`timestamp_hourly`)\n",
    "* The y-axis shows the trait values\n",
    "* The data is filtered to include **all genotypes**\n",
    "* Each line represents a plant, and the **line color shows which treatment** that plant received\n",
    "* The title indicates the trait and that it's colored by `\"Treatment\"`\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **Why This Is Useful**\n",
    "\n",
    "* Helps you compare **treatment effects within each genotype** across time.\n",
    "* Useful for evaluating if **certain genotypes respond differently** to stress, nutrient regimes, etc.\n",
    "* Makes it easy to spot **divergent trends**—for example, if one genotype maintains growth under drought, while another declines.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Example Interpretation\n",
    "\n",
    "If you see:\n",
    "\n",
    "* All lines for one genotype in the `\"Drought\"` treatment drop in `digital_biomass`, while the `\"Control\"` lines rise steadily, this might suggest that genotype is **sensitive to drought**.\n",
    "* Another genotype might show similar trends across treatments, suggesting **tolerance or resistance**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGenotypePanel(phenotypic_data, phenotypic_data[\"Genotype\"].unique(), hue=\"Treatment\", legend=True,traits=[\"leaf_inclination\", \"leaf_angle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotGenotypes(phenotypic_data, phenotypic_data[\"Genotype\"].unique(), hue=\"Treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌾 Vegetation Indices Provided by PlantEye F500\n",
    "\n",
    "Vegetation indices are mathematical combinations of spectral reflectance values (typically in the Red, Green, Blue, and Near-Infrared wavelengths) that provide insights into plant physiology, health, and stress status. The following indices are calculated directly from the multispectral data captured by the PlantEye F500:\n",
    "\n",
    "---\n",
    "\n",
    "### 🌿 1. **Greenness Index**\n",
    "- **Purpose:** Measures the relative contribution of green light reflectance to overall reflectance, indicating general \"greenness\" of vegetation.\n",
    "- **Formula:**  \n",
    "  \\[\n",
    "  \\text{Greenness} = \\frac{G}{R + G + B}\n",
    "  \\]\n",
    "- **Where:**\n",
    "  - \\( G \\): Green reflectance\n",
    "  - \\( R \\): Red reflectance\n",
    "  - \\( B \\): Blue reflectance\n",
    "- **Interpretation:** Higher values generally correspond to healthy, green plant tissue.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 2. **Normalized Difference Vegetation Index (NDVI)**\n",
    "- **Purpose:** A widely used index for estimating vegetation health and biomass.\n",
    "- **Formula:**  \n",
    "  \\[\n",
    "  \\text{NDVI} = \\frac{NIR - R}{NIR + R}\n",
    "  \\]\n",
    "- **Where:**\n",
    "  - \\( NIR \\): Near-Infrared reflectance\n",
    "  - \\( R \\): Red reflectance\n",
    "- **Interpretation:** Values range from -1 to 1.\n",
    "  - Healthy vegetation typically has NDVI > 0.5\n",
    "  - Bare soil or stressed vegetation has NDVI near 0 or negative\n",
    "\n",
    "---\n",
    "\n",
    "### 🍂 3. **Plant Senescence Reflectance Index (PSRI)**\n",
    "- **Purpose:** Detects leaf senescence (aging), linked to pigment degradation (e.g., chlorophyll breakdown).\n",
    "- **Formula:**  \n",
    "  \\[\n",
    "  \\text{PSRI} = \\frac{R - G}{NIR}\n",
    "  \\]\n",
    "- **Where:**\n",
    "  - \\( R \\): Red reflectance\n",
    "  - \\( G \\): Green reflectance\n",
    "  - \\( NIR \\): Near-Infrared reflectance\n",
    "- **Interpretation:** Higher values indicate increased senescence.\n",
    "\n",
    "---\n",
    "\n",
    "### 🎨 4. **Hue**\n",
    "- **Purpose:** Represents the **dominant color** of the plant surface in HSV (Hue, Saturation, Value) color space.\n",
    "- **Formula:**  \n",
    "  Calculated from RGB reflectance values using standard color-space conversion.\n",
    "- **Interpretation:**  \n",
    "  Hue values range from 0–360°, where:\n",
    "  - Green ~ 90–150°\n",
    "  - Yellow/Orange ~ 30–60°\n",
    "  - Red ~ 0–30° or 330–360°\n",
    "- Useful for detecting color changes due to stress or senescence.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌕 5. **Normalized Pigment Chlorophyll Index (NPCI)**\n",
    "- **Purpose:** Estimates pigment composition, especially the chlorophyll to carotenoid ratio.\n",
    "- **Formula:**  \n",
    "  \\[\n",
    "  \\text{NPCI} = \\frac{R - B}{R + B}\n",
    "  \\]\n",
    "- **Where:**\n",
    "  - \\( R \\): Red reflectance\n",
    "  - \\( B \\): Blue reflectance\n",
    "- **Interpretation:** Higher NPCI values often indicate chlorophyll loss and increasing carotenoid presence (a sign of stress or aging).\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Summary Table\n",
    "\n",
    "| Index     | Indicates                      | Formula                                      |\n",
    "|-----------|--------------------------------|----------------------------------------------|\n",
    "| Greenness | Vegetative vigor               | \\( \\frac{G}{R + G + B} \\)                     |\n",
    "| NDVI      | Biomass, vegetation health     | \\( \\frac{NIR - R}{NIR + R} \\)                |\n",
    "| PSRI      | Leaf senescence                | \\( \\frac{R - G}{NIR} \\)                      |\n",
    "| Hue       | Color/hue shift in foliage     | From RGB (HSV conversion)                    |\n",
    "| NPCI      | Chlorophyll-to-carotenoid ratio| \\( \\frac{R - B}{R + B} \\)                    |\n",
    "\n",
    "---\n",
    "\n",
    "These indices are powerful tools for **non-invasive monitoring** of plant condition and development, and they can be used to detect **early stress symptoms** or evaluate treatment effects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram data\n",
    "\n",
    "This section analyzes **index histograms greenness, NDVI, PSRI, hue and NPCI**—which provide insights into how vegetation index values are distributed across an individual plant or plot at different timepoints.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **Index Histogram Analysis**\n",
    "\n",
    "The goal of this process is to **visualize how the distribution** of a vegetation index (e.g., `greenness`, `NDVI`, `NPCI`) changes **over time** for a specific plant (or sample). These distributions are stored as **histograms** in CSV files, where each histogram consists of **256 bins** representing the range of possible index values.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Function 1: `get_histogram(index=\"greenness\", sample=None)`\n",
    "\n",
    "#### 🔧 **Purpose**\n",
    "\n",
    "This function collects histogram data for a specific vegetation index (e.g., `\"greenness\"`), optionally for a single sample (plant). It returns a single DataFrame containing:\n",
    "\n",
    "* The histogram values\n",
    "* Associated timepoints\n",
    "* The bin edges (value ranges)\n",
    "\n",
    "---\n",
    "\n",
    "#### 📥 **Inputs**\n",
    "\n",
    "* `index`: Which vegetation index to load (e.g., `\"greenness\"`, `\"ndvi\"`, etc.)\n",
    "* `sample`: (Optional) Limit to a specific sample name (pot ID)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **How It Works**\n",
    "\n",
    "1. **Loops through all assays** in the experiment.\n",
    "2. For each assay, checks if there's a matching histogram CSV file (based on index name).\n",
    "3. Reads in the histogram file, skipping metadata rows labeled `\"edges\"` except the first time (which provides bin definitions).\n",
    "4. Combines all individual histograms into one DataFrame.\n",
    "5. Converts timestamps and extracts calendar days.\n",
    "6. **Renames the columns** (originally labeled `bin0`, `bin1`, ..., `bin256`) to reflect the actual **value ranges** (e.g., index values from 0 to 1).\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 Function 2: `plotHistogram(sample, index)`\n",
    "\n",
    "#### 🔧 **Purpose**\n",
    "\n",
    "Visualizes the histogram distribution of an index at **two key timepoints**: the **earliest** and **latest** day available in the dataset. This shows how the index distribution shifts over time for a single plant.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📥 **Inputs**\n",
    "\n",
    "* `sample`: The histogram data returned from `get_histogram()`\n",
    "* `index`: The index being plotted (used for labeling)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **How It Works**\n",
    "\n",
    "1. **Reshapes the DataFrame** from wide format (one row per histogram) to long format (one row per bin value).\n",
    "2. Finds the **first and last day** in the dataset.\n",
    "3. Calculates the **relative frequency** of each bin value (normalized by total count per day).\n",
    "4. Uses **Seaborn** to plot two line graphs:\n",
    "\n",
    "   * x-axis: Bin value (actual index value range)\n",
    "   * y-axis: Normalized frequency\n",
    "   * Lines: One for the first day, one for the last day\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **Why Histogram Analysis Matters**\n",
    "\n",
    "* **Index histograms show internal variation** within a plant or canopy—not just averages.\n",
    "* You can see how **stress, growth, or senescence shifts** the distribution of spectral traits.\n",
    "* For example, a shift in NDVI from high to low bins might indicate chlorophyll degradation or reduced greenness.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Example Use\n",
    "\n",
    "```python\n",
    "hist = get_histogram(index=\"greenness\", sample=\"Pot_123\")\n",
    "plotHistogram(hist, index=\"greenness\")\n",
    "```\n",
    "\n",
    "This would show how the **greenness index distribution** for pot `\"Pot_123\"` evolved from the start to the end of the experiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(index = \"greenness\", sample = None):\n",
    "    histogram_list = []\n",
    "    for assay in study.assays:\n",
    "        sample_name = assay.samples[0].name\n",
    "        timepoint = assay.filename\n",
    "        if sample != None:\n",
    "            if sample_name != sample:\n",
    "                continue\n",
    "        for df in assay.data_files:\n",
    "            for com in df.comments:\n",
    "                if com.name == \"fullPath\" and \"_\" + index + \".csv\" in com.value:\n",
    "                    histogram_file =  data_folder + com.value\n",
    "                    try:\n",
    "                        histogram_data = pd.read_csv(histogram_file, sep=\";\")\n",
    "                        if len(histogram_list) > 0:\n",
    "                            histogram_data = histogram_data[histogram_data[\"sample\"] != \"edges\"]\n",
    "                        histogram_list.append(histogram_data) \n",
    "                    except Exception as e:\n",
    "                        #print(\"Could not process histogram file: {}\".format(e))\n",
    "                        pass\n",
    "    histogram = pd.DataFrame()\n",
    "    if len(histogram_list) == 0:\n",
    "        print(\"No histogram data found\")\n",
    "    else:\n",
    "        histogram = pd.concat(histogram_list, axis=0, ignore_index=True)\n",
    "        histogram[\"timepoint\"]= histogram[\"timepoint\"].apply(lambda x: dt.datetime.strptime(x, '%Y%m%dT%H%M%S'))\n",
    "        histogram[\"day\"] = histogram[\"timepoint\"].dt.date\n",
    "        # rename bin column names\n",
    "        xAxis = histogram[histogram[\"sample\"] == \"edges\"]\n",
    "        xAxis = xAxis.drop(columns=[\"day\", \"timepoint\", \"sample\"])\n",
    "        xAxis = xAxis.loc[0, :].values.flatten().tolist()\n",
    "        columns = {}\n",
    "        for c in range(0,257):\n",
    "            columns[\"bin{}\".format(c)] = xAxis[c]\n",
    "        histogram = histogram.rename(columns=columns)\n",
    "\n",
    "    return histogram\n",
    "\n",
    "def plotHistogram(sample, index, start_date=None):\n",
    "    sample_melt = sample.melt(id_vars=[\"sample\", \"day\", \"timepoint\"])\n",
    "    group_by = 'timepoint'  # Use timepoint for normalization\n",
    "    #group_by = 'day'\n",
    "\n",
    "    if start_date is not None:\n",
    "        sample_melt = sample_melt[sample_melt[\"timepoint\"] >= start_date]\n",
    "    if group_by == 'day':\n",
    "        minDate = min(sample_melt[\"day\"])\n",
    "        maxDate = max(sample_melt[\"day\"])\n",
    "    else:\n",
    "        minDate = min(sample_melt[\"timepoint\"])\n",
    "        maxDate = max(sample_melt[\"timepoint\"])\n",
    "\n",
    "    #print(minDate)\n",
    "    #print(maxDate)\n",
    "\n",
    "    #Normalize by total count\n",
    "    sample_melt['total_count'] = sample_melt.groupby(group_by)['value'].transform('sum')  # Total greenness values per day\n",
    "    sample_melt['value_normalized'] = sample_melt['value'] / sample_melt['total_count']  # Normalize greenness\n",
    "\n",
    "    # Plot the normalized values\n",
    "    ax = sns.lineplot(data=sample_melt[(sample_melt[group_by] == minDate) | (sample_melt[group_by] == maxDate)],\n",
    "                    x=\"variable\", y=\"value_normalized\", hue=group_by, errorbar=None)\n",
    "    #ax = sns.lineplot(data = sample_melt[(sample_melt[\"day\"] == minDate) | (sample_melt[\"day\"] == maxDate)], x=\"variable\", y=\"value\", hue=\"day\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"{} for {}\".format(index, sample_name))\n",
    "    plt.xlabel(index)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index plots\n",
    "\n",
    "## 🔄 **Looping Through Samples and Indices for Histogram Analysis**\n",
    "\n",
    "This code block automates the process of **loading and plotting vegetation index histograms** for **each individual plant (pot)** in your dataset, across selected indices.\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 **What's Happening**\n",
    "\n",
    "```python\n",
    "for sample_name in phenotypic_data[\"Pot\"].unique():\n",
    "```\n",
    "\n",
    "* Loops through **each unique plant/pot** in your dataset.\n",
    "* This ensures that every individual plant is analyzed.\n",
    "\n",
    "```python\n",
    "    for index in [\"greenness\", \"hue\", \"ndvi\"]:\n",
    "```\n",
    "\n",
    "* For each plant, loop through three important vegetation indices:\n",
    "\n",
    "  * `greenness`: General vigor and chlorophyll presence\n",
    "  * `hue`: Color shift, potentially due to senescence or pigment change\n",
    "  * `ndvi`: Vegetation health and biomass\n",
    "\n",
    "```python\n",
    "        sample = get_histogram(index, sample_name)\n",
    "        plotHistogram(sample, index)\n",
    "```\n",
    "\n",
    "* Retrieves the **histogram data** for that sample and index.\n",
    "* Then generates a **timepoint comparison plot** showing how the index distribution changed from the start to the end of the experiment.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **What You'll See**\n",
    "\n",
    "For each plant and index:\n",
    "\n",
    "* A **line plot** comparing the index distribution at two timepoints (earliest and latest).\n",
    "* X-axis shows index value bins (e.g., NDVI from 0 to 1).\n",
    "* Y-axis shows **normalized frequency**, showing how index values are distributed across the plant’s canopy.\n",
    "* This helps you **visually detect trends**, such as:\n",
    "\n",
    "  * Increase in lower NDVI values (possible stress)\n",
    "  * Shift in hue (e.g., green to yellow/red due to senescence)\n",
    "  * Flattening of greenness distribution (loss of uniformity)\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **Why This Is Useful**\n",
    "\n",
    "* Helps assess **per-plant variation over time**, rather than relying on averages across treatments or genotypes.\n",
    "* Reveals **early signs of stress** or changes that might be missed by summary statistics.\n",
    "* Supports visual **comparison of plant responses** to environment or treatment conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_name in metadata[\"Pot\"].unique()[:4]:\n",
    "    #for index in [\"greenness\", \"hue\", \"ndvi\"]:\n",
    "    for index in [\"greenness\"]:\n",
    "        sample = get_histogram(index, sample_name)\n",
    "        plotHistogram(sample, index, start_date=threshold_date)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of top view images\n",
    "\n",
    "This function is designed to **load and display top-view images** of 3D point clouds, either **RGB** or **NDVI-rendered**, for a given plant sample across multiple timepoints.\n",
    "\n",
    "---\n",
    "\n",
    "## 🌄 **Top-View Image Display Function**\n",
    "\n",
    "### 🧩 Function: `get_images(type=\"RGB\", sample=None)`\n",
    "\n",
    "#### 🔧 **Purpose**\n",
    "\n",
    "This function loads and displays a **series of top-view images** (either **RGB** or **NDVI**) of a selected plant sample over time. These images are generated from 3D point clouds collected by the **PlantEye F500**, and they provide a visual reference of plant structure and health.\n",
    "\n",
    "---\n",
    "\n",
    "### 📥 **Inputs**\n",
    "\n",
    "* `type`: Type of image to load.\n",
    "\n",
    "  * `\"RGB\"` (default): Standard color image generated from the point cloud.\n",
    "  * `\"NDVI\"` or `\"ndvi\"`: False-color NDVI image showing vegetation health.\n",
    "* `sample`: (Optional) A specific plant (pot) name. If left `None`, the function processes **all samples**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **How It Works**\n",
    "\n",
    "1. **Loop through each assay** (i.e., each timepoint and sample):\n",
    "\n",
    "   * Extract sample name and timepoint (timestamp).\n",
    "   * Check if the image file exists for the desired `type` (`.png` for RGB, `.ndvi.PNG` for NDVI).\n",
    "   * Identify matching file paths using metadata from the ISA-JSON structure.\n",
    "   * Append image file information (path and date) to a list.\n",
    "\n",
    "2. **Filter valid files only**:\n",
    "\n",
    "   * Ensures only existing image files (on disk) are included.\n",
    "\n",
    "3. **Sort images by date**:\n",
    "\n",
    "   * Converts timestamp strings to `datetime` and sorts chronologically.\n",
    "\n",
    "4. **Prepare and display images using matplotlib**:\n",
    "\n",
    "   * Dynamically adjusts grid size based on number of images.\n",
    "   * Resizes each image for consistent display.\n",
    "   * Disables axes for a cleaner look.\n",
    "   * Shows the full set of time-sequenced top-view images.\n",
    "\n",
    "---\n",
    "\n",
    "### 🖼️ **What You’ll See**\n",
    "\n",
    "* A **grid of images**, one for each scan of the selected plant (or all plants, if no sample is specified).\n",
    "* Each image represents a **top-down view** of the plant at a specific timepoint.\n",
    "* If `type=\"NDVI\"`, the images use a color scale to show vegetation index intensity (e.g., green = healthy, red/yellow = stressed).\n",
    "* Useful for visual inspection of **plant development** or **treatment effects** over time.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 **Example Use Cases**\n",
    "\n",
    "```python\n",
    "get_images(type=\"RGB\", sample=\"Pot_101\")\n",
    "```\n",
    "\n",
    "Displays **RGB top views** of `Pot_101` over the experiment timeline.\n",
    "\n",
    "```python\n",
    "get_images(type=\"NDVI\")\n",
    "```\n",
    "\n",
    "Displays **NDVI top views** for all samples (if present), sorted by scan date.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌱 **Why This Is Useful**\n",
    "\n",
    "* **Visual context**: Complements numeric trait data with qualitative visual cues.\n",
    "* Helps detect **outliers**, damage, or scanner issues.\n",
    "* Facilitates quick comparisons between RGB appearance and NDVI health signals.\n",
    "* Valuable for **presentations**, **quality control**, and **hypothesis generation**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(type = \"RGB\", sample = None):\n",
    "    image = pd.DataFrame(columns=[\"date\", \"name\"])\n",
    "    for assay in study.assays:\n",
    "        sample_name = assay.samples[0].name\n",
    "        timepoint = assay.filename\n",
    "        extension = \".png\"\n",
    "        if type in [\"NDVI\", \"ndvi\"]:\n",
    "            extension = \".ndvi.PNG\"\n",
    "        if sample != None:\n",
    "            if sample_name != sample:\n",
    "                continue\n",
    "        for df in assay.data_files:\n",
    "            for com in df.comments:\n",
    "                if \"ply.gz\" in com.value and \"full\" in com.value:\n",
    "                    new_row = pd.DataFrame([{\n",
    "                        \"date\": timepoint,\n",
    "                        \"name\": data_folder + com.value + extension}])\n",
    "\n",
    "                    image = pd.concat([image, new_row], ignore_index=True)\n",
    "                    #print(\"Found image file: {}\".format(com.value))\n",
    "    image = image[image[\"name\"].apply(lambda x: os.path.exists(x))].reset_index(drop=True)\n",
    "    # Convert 'date' column to datetime for sorting\n",
    "    image['date'] = pd.to_datetime(image['date'], format='%Y%m%dT%H%M%S')\n",
    "\n",
    "    # Sort the dataframe by date\n",
    "    image = image.sort_values(by='date')\n",
    "    # Filter images by threshold_date if available\n",
    "    image = image[image['date'] >= threshold_date]\n",
    "\n",
    "    # Extract all the file names\n",
    "    image_files = image['name'].tolist()\n",
    "\n",
    "\n",
    "    max_cols = 5\n",
    "    num_images = len(image_files)\n",
    "    # Calculate number of rows needed\n",
    "    rows = math.ceil(num_images / max_cols)\n",
    "    cols = min(num_images, max_cols)\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    if isinstance(axes, np.ndarray):\n",
    "        axes_flat = axes.flatten()\n",
    "    else:\n",
    "        axes_flat = [axes]\n",
    "\n",
    "    # Display images\n",
    "    for i in range(num_images):\n",
    "        ax = axes_flat[i]\n",
    "        img = Image.open(image_files[i])\n",
    "        img.thumbnail((200, 200))\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    # Hide any unused axes\n",
    "    for j in range(num_images, len(axes_flat)):\n",
    "        axes_flat[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_images(\"RGB\",  \"NPEC53.20250611.JU4.B1WUR017.WR.5\")\n",
    "get_images(\"ndvi\",  \"NPEC53.20250611.JU4.B1WUR017.WR.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌱 **Plant Vigor: What It Is and How It's Measured**\n",
    "\n",
    "### 🌿 **What Is Plant Vigor?**\n",
    "\n",
    "**Plant vigor** refers to the **rate of growth** or **growth potential** of a plant over time. It reflects how rapidly a plant is accumulating biomass, which can be influenced by:\n",
    "\n",
    "* Genetics (e.g., genotype differences)\n",
    "* Environmental conditions (light, temperature, soil)\n",
    "* Treatments (fertilization, drought, etc.)\n",
    "\n",
    "In high-throughput phenotyping (like with the PlantEye F500), **vigor is typically derived from changes in digital biomass over time**.\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 **What This Code Does: Calculating and Plotting Vigor**\n",
    "\n",
    "This section calculates plant vigor based on **digital biomass measurements** over time and visualizes both the **growth rate (vigor)** and the **biomass accumulation** itself.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 **Step-by-Step Code Documentation**\n",
    "\n",
    "#### 1. **Select a Sample Plant**\n",
    "\n",
    "```python\n",
    "sample = \"GJ1\"\n",
    "vigor = phenotypic_data[phenotypic_data['Pot'] == sample].sort_values(by=['Pot', 'timestamp'])\n",
    "```\n",
    "\n",
    "* Filters the dataset to include only measurements for a specific plant pot (`GJ1`).\n",
    "* Sorts the data by timestamp to ensure it's in chronological order.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Define Time Resolution for Smoothing**\n",
    "\n",
    "```python\n",
    "resample_interval = '12h'\n",
    "```\n",
    "\n",
    "* Sets the time resolution to **12-hour intervals**.\n",
    "* This controls how often we calculate estimated biomass values by interpolation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Resample and Interpolate Biomass**\n",
    "\n",
    "```python\n",
    "def interpolate_biomass(df):\n",
    "    ...\n",
    "```\n",
    "\n",
    "* This function:\n",
    "\n",
    "  * **Resamples the biomass values** at uniform time intervals (12 hours).\n",
    "  * **Interpolates missing values** using a 3rd-order polynomial, smoothing the curve.\n",
    "  * **Applies a rolling average** to reduce noise.\n",
    "* The result is a **smoothed, continuous digital biomass curve** over time.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Apply the Interpolation**\n",
    "\n",
    "```python\n",
    "df_interpolated = interpolate_biomass(vigor)\n",
    "```\n",
    "\n",
    "* Applies the above function to the sample's data.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Calculate Growth Rate (Vigor)**\n",
    "\n",
    "```python\n",
    "df_interpolated['time_change'] = ...\n",
    "df_interpolated['biomass_change'] = ...\n",
    "df_interpolated['vigor'] = df_interpolated['biomass_change'] / df_interpolated['time_change']\n",
    "```\n",
    "\n",
    "* Computes the **time difference** between each measurement (in hours).\n",
    "* Calculates how much **biomass has changed** between timepoints.\n",
    "* Divides biomass change by time difference → this is **vigor** (biomass gain per hour).\n",
    "* Applies smoothing to biomass change to handle measurement noise.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. **Clean and Visualize**\n",
    "\n",
    "```python\n",
    "df_interpolated = df_interpolated.dropna(...)\n",
    "plt.plot(df_interpolated['timestamp'], df_interpolated['vigor'], ...)\n",
    "```\n",
    "\n",
    "* Removes initial `NaN` values that result from `.diff()` (which calculates change).\n",
    "* Plots **vigor over time** (how fast the plant is growing).\n",
    "* Then plots **digital biomass over time** (how much biomass has accumulated).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **What You Learn From the Plots**\n",
    "\n",
    "* **Vigor Plot**: Helps identify when the plant was growing fastest (high vigor) and when growth slowed or stopped (low/zero vigor).\n",
    "* **Biomass Plot**: Shows the overall **growth curve** of the plant over the course of the experiment.\n",
    "\n",
    "Together, they give a **dynamic picture** of growth — not just the final size, but **how and when** growth occurred.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 Example Applications\n",
    "\n",
    "* Compare **vigor patterns across genotypes** or treatments.\n",
    "* Identify **critical growth periods** (e.g., early vigor boost under fertilizer).\n",
    "* Detect **growth slowdowns** due to stress or senescence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to calculate vigor for\n",
    "sample = \"GJ1\"\n",
    "\n",
    "# Filter data for the specific sample and sort by 'timestamp'\n",
    "vigor = phenotypic_data[phenotypic_data['Pot'] == sample].sort_values(by=['Pot', 'timestamp'])\n",
    "\n",
    "# Define the time interval for interpolation (e.g., every 1 hour)\n",
    "resample_interval = '12h'  # or '6H', '12H', etc. depending on the desired frequency\n",
    "\n",
    "# Function to interpolate biomass for a single sample\n",
    "def interpolate_biomass(df):\n",
    "    # Set 'timestamp' as the index to allow resampling\n",
    "    df = df.set_index('timestamp')\n",
    "\n",
    "    # Resample biomass at the defined interval and interpolate missing values\n",
    "    resampled_df = df[['digital_biomass']].resample(resample_interval).mean()  # Resample every X hours\n",
    "\n",
    "    # Interpolate only the 'digital_biomass' column\n",
    "    resampled_df['digital_biomass'] = resampled_df['digital_biomass'].interpolate(method='polynomial', order=3)\n",
    "    resampled_df['digital_biomass'] = resampled_df['digital_biomass'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "    # Forward fill 'Pot' (non-numeric column)\n",
    "    resampled_df['Pot'] = df['Pot'].ffill()\n",
    "\n",
    "    # Reset index to return to the original structure\n",
    "    return resampled_df.reset_index()\n",
    "\n",
    "# Directly apply interpolation without using apply() (since we're working with a single sample)\n",
    "df_interpolated = interpolate_biomass(vigor)\n",
    "\n",
    "# Calculate the time difference (in hours) between consecutive time points\n",
    "df_interpolated['time_change'] = df_interpolated['timestamp'].diff().dt.total_seconds() / 3600.0\n",
    "\n",
    "# Calculate the biomass change\n",
    "df_interpolated['biomass_change'] = df_interpolated['digital_biomass'].diff()\n",
    "df_interpolated['biomass_change'] = df_interpolated['biomass_change'].interpolate(method='polynomial', order=3)\n",
    "df_interpolated['biomass_change'] = df_interpolated['biomass_change'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "# Calculate vigor (biomass change per hour)\n",
    "df_interpolated['vigor'] = df_interpolated['biomass_change'] / df_interpolated['time_change']\n",
    "\n",
    "# Drop NaN values created by diff() in the first row\n",
    "df_interpolated = df_interpolated.dropna(subset=['time_change', 'biomass_change'])\n",
    "\n",
    "# Plot the vigor over time for the sample\n",
    "plt.plot(df_interpolated['timestamp'], df_interpolated['vigor'], label=sample)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Vigor (digital biomass change per hour)')\n",
    "plt.title(f'Vigor Over Time for Sample {sample}')\n",
    "plt.legend(title='Sample')\n",
    "plt.show()\n",
    "\n",
    "# Plot the biomass over time for the sample\n",
    "plt.plot(df_interpolated['timestamp'], df_interpolated['digital_biomass'], label=sample)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Digital biomass')\n",
    "plt.title(f'Digital biomass over time {sample}')\n",
    "plt.legend(title='Sample')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "# Step 1: Group by 'Pot' and compute max, min, and Position\n",
    "summary = phenotypic_data.groupby('Pot').agg(\n",
    "    Max=('height', 'max'),\n",
    "    Min=('height', 'min'),\n",
    "    Position=('Position', 'first')  # assuming Position is consistent per Pot\n",
    ").reset_index()\n",
    "\n",
    "# Step 2: Compute Glare condition\n",
    "#summary['Glare'] = (summary['Max'] - summary['Min']) > (0.8 * summary['Max'])\n",
    "summary['Glare'] = (summary['Max']  > 200)\n",
    "# Step 3: Keep only required columns\n",
    "result = summary[['Pot', 'Position', 'Glare']]\n",
    "\n",
    "# Display result\n",
    "print(result)\n",
    "\n",
    "# Assume 'result' is your DataFrame with columns: Pot, Position, Glare\n",
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "# result = pd.DataFrame({\n",
    "#     'Pot': ['P1', 'P2', 'P3', 'P4'],\n",
    "#     'Position': ['KB23', 'KA01', 'KB01', 'KA23'],\n",
    "#     'Glare': [True, False, True, False]\n",
    "# })\n",
    "\n",
    "# Step 1: Extract Table, Column, Row\n",
    "result['Table'] = result['Position'].str[0]\n",
    "result['Column'] = result['Position'].str[1]\n",
    "result['Row'] = result['Position'].str[2:].astype(int)\n",
    "\n",
    "# Step 2: Sort\n",
    "result = result.sort_values(by=['Table', 'Column', 'Row'])\n",
    "\n",
    "# Step 3: Plot one grid per table\n",
    "tables = result['Table'].unique()\n",
    "\n",
    "for table in tables:\n",
    "    table_data = result[result['Table'] == table]\n",
    "    \n",
    "    cols = sorted(table_data['Column'].unique())\n",
    "    rows = sorted(table_data['Row'].unique())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(len(cols), len(rows)))\n",
    "    ax.set_title(f\"Table {table}\")\n",
    "    \n",
    "    for _, row in table_data.iterrows():\n",
    "        col_idx = cols.index(row['Column'])\n",
    "        row_idx = rows.index(row['Row'])\n",
    "        color = 'red' if row['Glare'] else 'green'\n",
    "        ax.add_patch(plt.Rectangle((col_idx, row_idx), 1, 1, color=color))\n",
    "        ax.text(col_idx + 0.5, row_idx + 0.5, row['Pot'], ha='center', va='center', color='white', fontsize=8)\n",
    "    \n",
    "    ax.set_xlim(0, len(cols))\n",
    "    ax.set_ylim(0, len(rows))\n",
    "    ax.set_xticks(np.arange(len(cols)) + 0.5)\n",
    "    ax.set_xticklabels(cols)\n",
    "    ax.set_yticks(np.arange(len(rows)) + 0.5)\n",
    "    ax.set_yticklabels(rows)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True)\n",
    "\n",
    "    red_patch = mpatches.Patch(color='red', label='Glare')\n",
    "    green_patch = mpatches.Patch(color='green', label='No Glare')\n",
    "    ax.legend(handles=[red_patch, green_patch], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
